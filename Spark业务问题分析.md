## Spark业务问题分析


----------
### **性能调优**
#### 1. 若干task拖慢整个job进程
￼￼![Alt text](https://github.com/alixGuo/resources/blob/master/2016111101.jpg)
如图中红框中的四个任务，单个task处理的数据条数是其他任务的10倍以上，导致这四个任务耗时很长。

> **问题分析**：任务耗时很长的原因是源数据的压缩比很高，47M的数据里面有6000多万条数据，虽然计算逻辑很简单，task执行的时间还是很长。而且这47M的数据还在一个block里面，导致解压和map操作由一个task来执行。从数据看GC也不是瓶颈，所以无论通过增加executor数目还是内存都无法将问题改善。
> 
> **解决方案**：如果数据压缩比不大的话，数据可以分布在不同的block中，数据条数就会均衡一点。
